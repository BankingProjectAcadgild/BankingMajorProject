{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This file has request-response module to get PAN images from user and convert to JSON using google VISION API response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pdf2image\n",
    "# !sudo apt install poppler-utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import requests\n",
    "import base64\n",
    "import re\n",
    "import PIL.ImageOps\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "import json\n",
    "from PIL import ImageEnhance\n",
    "import time\n",
    "from pdf2image import convert_from_path\n",
    "import collections\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "##CALLING OCR API\n",
    "def detect_image_text(image):\n",
    "  url = 'https://vision.googleapis.com/v1/images:annotate?'\n",
    "  res = []\n",
    "  img_base64 = base64.b64encode(image)\n",
    "  ig = str(img_base64)\n",
    "  ik=ig.replace('b\\'','')\n",
    "  headers={'content-type': 'application/json'}\n",
    "  data =\"\"\"{\n",
    "    \"requests\": [\n",
    "      {\n",
    "        \"image\": {\n",
    "                 \"content\": '\"\"\"+ik[:-1]+\"\"\"'\n",
    "\n",
    "                  },\n",
    "\n",
    "        \"features\": [\n",
    "          {\n",
    "            \"type\": \"DOCUMENT_TEXT_DETECTION\"\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "    ]\n",
    "  }\"\"\"\n",
    "  r = requests.post(url, headers=headers,data=data)\n",
    "  result = json.loads(r.text)\n",
    "  return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_ocr1(r):\n",
    "    try:\n",
    "        r['responses'][0]['textAnnotations'][1:]  \n",
    "    except:\n",
    "        return('0')\n",
    "        \n",
    "    word_infos = []\n",
    "    for i, number in enumerate(r['responses'][0]['textAnnotations']):\n",
    "        dic = dict()\n",
    "        rect = r['responses'][0]['textAnnotations'][i]['boundingPoly']['vertices']\n",
    "        text = r['responses'][0]['textAnnotations'][i]['description']\n",
    "        pt1 = []\n",
    "        pt2 = []\n",
    "        try:\n",
    "            pt1 = [rect[0]['x'], rect[0]['y']]\n",
    "            pt2 = [rect[2]['x'], rect[2]['y']]\n",
    "        except:\n",
    "             continue\n",
    "        dic['boundingBox_list'] = pt1 + pt2\n",
    "        pt1.extend([-pt1[0] + pt2[0], -pt1[1] + pt2[1]])\n",
    "        #str(round(pt1))\n",
    "        dic['boundingBox'] = ', '.join(repr(e) for e in pt1)\n",
    "        dic['text'] = text\n",
    "        word_infos.append(dic)\n",
    "    word_info = word_infos[1:len(word_infos)]\n",
    "    urls = []\n",
    "    urlls=[]\n",
    "    box_cordinate_list = []\n",
    "    ##########extract only text and boundingbox from dict\n",
    "    for i in range(len(word_info)):\n",
    "        box_cordinate_list.append(word_info[i]['boundingBox_list'])\n",
    "        urls.append(word_info[i]['text'])\n",
    "        urlls.append(word_info[i]['boundingBox'])\n",
    "\n",
    "    df = pd.DataFrame({'Rows':urls, 'Co-ordinates':urlls})\n",
    "    df  = pd.concat([df['Rows'],df['Co-ordinates'].str.split(\",\",expand= True)],axis =1)\n",
    "    df.columns = ['Rows21','X','Y','Xh','Yk']\n",
    "    df[['X','Y','Xh','Yk']] = df[['X','Y','Xh','Yk']].apply(pd.to_numeric)\n",
    "    df['Xh'] = df['X'] + df['Xh']\n",
    "    df['Yk'] = df['Y'] + df['Yk']\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be changed according to the images location\n",
    "\n",
    "os.chdir(r'C:\\Users\\Dell\\Desktop\\Acadgild\\project\\Bank_project\\resources\\pan_card')\n",
    "path = r'C:\\Users\\Dell\\Desktop\\Acadgild\\project\\Bank_project\\resources\\pan_card'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pan_number(df):\n",
    "  pan = \"\"\n",
    "  for i in range(0,len(df)):\n",
    "    text = df.iloc[i]['Rows21']\n",
    "    if(re.search(\"[A-Z]{5}[0-9]{4}[A-Z]\",text)):\n",
    "      pan = text\n",
    "      return pan\n",
    "  pan = \"not readable\"\n",
    "  return pan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'PAN_CARD_sample.png'\n",
    "new_file_name = filename\n",
    "image_bytes = open(new_file_name,'rb')\n",
    "image_bytes = image_bytes.read()\n",
    "image = np.array(Image.open(io.BytesIO(image_bytes)))\n",
    "image_bytes = cv2.imencode('.jpg',image)[1].tostring()\n",
    "response = detect_image_text(image_bytes)\n",
    "\n",
    "\n",
    "\n",
    "print(response)\n",
    "df = frequency_ocr1(response)\n",
    "print(df)\n",
    "PAN_NO = pan_number(df)\n",
    "print(PAN_NO)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  NOTE: use \"response\" variable output to parse json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
